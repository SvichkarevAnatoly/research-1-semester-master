\setcounter{figure}{0} \setcounter{table}{0} \setcounter{equation}{0}
\chapter*{ОСНОВНАЯ ЧАСТЬ}
\addcontentsline{toc}{section}{ОСНОВНАЯ ЧАСТЬ}
\section*{Теория метода DEEP}
\addcontentsline{toc}{subsection}{Теория метода DEEP}

Выделяют два класса задач, связанные с математическими моделями: это прямые и обратные.

В прямой задаче структура и параметры модели считаются известными, необходимо получить новую полезную информацию об объекте. Примером такой задачи может быть вычисление максимальной статической нагрузки на мост.

Для обратной задачи чаще всего модель известна, но не известны некоторые параметры модели. Задача заключается в нахождение этих параметров, например, из данных уже проведённых экспериментов, либо постановки дополнительных экспериментов, называемых активным наблюдением.

Примером обратной задачи математического моделирования может являться выявление параметров взаимодействий биологических молекул, которые не могут быть измерены напрямую из экспериментов. Формальная постановка данной задачи к минимизации некоего функционала качества при соблюдение ограничений на параметры.

Методы оптимизации можно классифицировать в соответствии с задачами оптимизации на локальные методы, которые сходятся к локальному экстремуму целевой функции (в случае унимодальной функции, экстремум единственный и одновременно является глобальным экстремумом) и глобальные методы, которые стремятся к выявлению глобальных тенденций поведения целевой функции и поиску глобального экстремума.

Примерами глобальных методов могут служить метод Численного отжига и различные генетические алгоритмы, как разностная эволюция и эволюционные стратегии.
Примером локального метода является градиентный спуск.
Если сравнивать данные методы по трудозатратности вычислительных ресурсов, то локальные методы работают быстрее, чем глобальные метода.
Однако, чтобы добиться хороших результатов для многоэкстремальных целевых функций локальным методам нужно иметь начальное приближение параметров.
Глобальные методы часто используют эвристики и не гарантируют оптимальности.

DEEP относится к глобальным прямым стохастическим (случайным) методам.
Это значит, что он способен недетерминированно (т.е. с использованием вероятностных методов) находить экстремум для многоэкстремальных целевых функций только с использованием вычисления целевой функции в точках приближения без требования вычисления частных производных функции.
Оригинальный метод разностной эволюции был разработан Рэйнером Сторном и Кеннетом Прайсом \cite{Storn95}.

Ниже приведено описание оригинального метода разностной эволюции и его модификации DEEP.

Разностная эволючия (РЭ) --- многомерный стохастический итерационный алгоритм минимизации.

Метод оперирует случайно сгенерированными векторами параметров, называемых индивидами. 
Под вектором понимается точка n-мерного пространства из области определения целевой функции, которую требуется минимизировать.
Множество индивидов называется популяцией.
Одна итерация популяции РЭ называется поколением.
Новое поколение генерируется случайным образом по заданной схеме из индивидов текущего поколения.

Идея генерации нового поколения в оригинальном алгоритме заключается в следующем.
Новое поколение генерируется в три этапа.
Для каждого индивида текущего поколения выбираются случайным образом 3 другие индивида из поколения и вычисляется мутантный вектор по формуле:

TODO

Производится операция скрещивания мутантного вектора с исходным, замещением некоторых координат значениями из исходного вектора.
Полученный вектор называется пробным вектором.
Если значение целевой функции на нём стало меньше, чем было на исходном, то пробный вектор добавляется в новое поколение.
Если нет, то в новое поколение переходит исходный индивид.
Таким образом, в каждом следующем поколение новые индивиды стремится уменьшить значение целевой функции и при определённых условиях может быть найден глобальный минимум.

Опишем две модификации РЭ, разработанной в \cite{KozlovThesis}.

TODO Скрещивание с учётом значения функционала.

TODO Скрещивание для поддержания разнообразия индивидов.

\section*{Программная реализация DEEP}
\addcontentsline{toc}{subsection}{Программная реализация DEEP}
TODO

\section*{Использование интерпретаторов}
\addcontentsline{toc}{subsection}{Использование интерпретаторов}
TODO

\section*{Тестовые функции}
\addcontentsline{toc}{subsection}{Тестовые функции}
TODO

\section*{Численные эксперименты}
\addcontentsline{toc}{subsection}{Численные эксперименты}
TODO

\section*{Сегментация траекторий частиц}
\addcontentsline{toc}{subsection}{Сегментация траекторий частиц}
TODO

